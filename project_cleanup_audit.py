#!/usr/bin/env python3
"""
Project Cleanup & Organization Audit
Analiza todos los scripts generados y categoriza por valor para la RELEASE
"""

import os
import glob
import subprocess
from datetime import datetime
from pathlib import Path


def analyze_project_files():
    """Analiza todos los archivos del proyecto y los categoriza"""

    print("üßπ PROJECT CLEANUP & ORGANIZATION AUDIT")
    print("üéØ Objetivo: Preparar para RELEASE manteniendo solo lo valioso")
    print("=" * 70)

    # Obtener todos los archivos Python
    python_files = glob.glob("*.py")

    categories = {
        'CORE_PRODUCTION': {
            'description': 'üèÜ Scripts CORE para PRODUCCI√ìN (MANTENER)',
            'files': [],
            'criteria': 'Sistema ML funcional, pipeline principal'
        },
        'VALUABLE_TOOLS': {
            'description': 'üîß Herramientas VALIOSAS (MANTENER & ORGANIZAR)',
            'files': [],
            'criteria': 'Utilidades para entrenamiento, an√°lisis, validaci√≥n'
        },
        'DEBUGGING_LEGACY': {
            'description': 'üêõ Scripts de DEBUGGING (ARCHIVAR)',
            'files': [],
            'criteria': 'Usados solo para encontrar problemas espec√≠ficos'
        },
        'EXPERIMENTAL': {
            'description': 'üß™ EXPERIMENTAL/TESTING (EVALUAR)',
            'files': [],
            'criteria': 'Experimentos, pruebas, versiones anteriores'
        },
        'DEPRECATED': {
            'description': 'üóëÔ∏è DEPRECATED (ELIMINAR)',
            'files': [],
            'criteria': 'Obsoletos, superados por versiones mejores'
        }
    }

    # Categorizaci√≥n basada en nombres y prop√≥sito
    file_categorization = {
        # CORE PRODUCTION - Lo que realmente funciona
        'fixed_service_sniffer.py': 'CORE_PRODUCTION',
        'sniffer_compatible_retrainer.py': 'CORE_PRODUCTION',

        # VALUABLE TOOLS - Herramientas √∫tiles
        'cicids_traditional_processor.py': 'VALUABLE_TOOLS',
        'cicids_retrainer.py': 'VALUABLE_TOOLS',
        'unsw_audit.py': 'VALUABLE_TOOLS',

        # DEBUGGING LEGACY - Usados para debugging espec√≠fico
        'debug_ml_network_sniffer.py': 'DEBUGGING_LEGACY',
        'auto_detect_ml_network_sniffer.py': 'DEBUGGING_LEGACY',
        'fixed_ml_network_sniffer.py': 'DEBUGGING_LEGACY',

        # EXPERIMENTAL - Experimentos durante desarrollo
        'cicids_kaggle_processor.py': 'EXPERIMENTAL',
        'advanced_trainer.py': 'EXPERIMENTAL',
        'advanced_trainer_no_dns.py': 'EXPERIMENTAL',

        # DEPRECATED - Versiones anteriores superadas
        'real_time_ml_network_sniffer.py': 'DEPRECATED',
        'threat-sniffer.py': 'DEPRECATED',
        'initial_trainer_models.py': 'DEPRECATED',
    }

    print("üìä CATEGORIZACI√ìN DE ARCHIVOS:")
    print()

    # Categorizar archivos encontrados
    for py_file in python_files:
        file_size = os.path.getsize(py_file) / 1024  # KB
        mod_time = datetime.fromtimestamp(os.path.getmtime(py_file))

        # Determinar categor√≠a
        category = file_categorization.get(py_file, 'EXPERIMENTAL')
        categories[category]['files'].append({
            'name': py_file,
            'size_kb': file_size,
            'modified': mod_time,
            'lines': count_lines(py_file)
        })

    # Mostrar resultados por categor√≠a
    for cat_name, cat_info in categories.items():
        if cat_info['files']:
            print(f"{cat_info['description']}")
            print(f"Criterio: {cat_info['criteria']}")

            for file_info in sorted(cat_info['files'], key=lambda x: x['modified'], reverse=True):
                print(f"   üìÑ {file_info['name']:<35} "
                      f"({file_info['size_kb']:>6.1f}KB, "
                      f"{file_info['lines']:>4d} l√≠neas, "
                      f"{file_info['modified'].strftime('%m/%d %H:%M')})")
            print()

    return categories


def count_lines(filename):
    """Cuenta l√≠neas de c√≥digo en un archivo"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return sum(1 for line in f if line.strip())
    except:
        return 0


def analyze_models_and_data():
    """Analiza modelos y datos generados"""

    print("ü§ñ AN√ÅLISIS DE MODELOS Y DATOS:")
    print("=" * 40)

    # Modelos
    model_files = glob.glob("models/*.joblib")
    if model_files:
        print("üìä MODELOS ENCONTRADOS:")
        for model in sorted(model_files):
            size_mb = os.path.getsize(model) / (1024 * 1024)
            mod_time = datetime.fromtimestamp(os.path.getmtime(model))

            # Categorizar modelos
            if 'sniffer_compatible' in model:
                status = "üèÜ PRODUCTION READY"
            elif 'cicids' in model:
                status = "‚úÖ CLEAN DATA"
            elif 'final' in model:
                status = "‚ùå CORRUPTED DATA"
            else:
                status = "üß™ EXPERIMENTAL"

            print(f"   {status:<20} {os.path.basename(model):<40} "
                  f"({size_mb:>5.1f}MB, {mod_time.strftime('%m/%d %H:%M')})")

    # Datos
    data_files = glob.glob("*.csv")
    if data_files:
        print("\nüìà DATASETS ENCONTRADOS:")
        for data in sorted(data_files):
            if os.path.getsize(data) > 1024 * 1024:  # > 1MB
                size_mb = os.path.getsize(data) / (1024 * 1024)
                mod_time = datetime.fromtimestamp(os.path.getmtime(data))

                # Categorizar datasets
                if 'cicids_2017_processed' in data:
                    status = "üèÜ CLEAN & PROCESSED"
                elif 'UNSW' in data:
                    status = "‚ùå CORRUPTED"
                else:
                    status = "üìä DATA"

                print(f"   {status:<20} {os.path.basename(data):<40} "
                      f"({size_mb:>6.1f}MB, {mod_time.strftime('%m/%d %H:%M')})")

    print()


def generate_cleanup_recommendations():
    """Genera recomendaciones de limpieza espec√≠ficas"""

    print("üí° RECOMENDACIONES DE LIMPIEZA:")
    print("=" * 40)

    recommendations = {
        "MANTENER & ORGANIZAR": [
            "fixed_service_sniffer.py ‚Üí core/ml_sniffer.py",
            "sniffer_compatible_retrainer.py ‚Üí tools/model_trainer.py",
            "cicids_traditional_processor.py ‚Üí tools/dataset_processor.py",
            "models/rf_production_sniffer_compatible.joblib ‚Üí models/production/",
            "cicids_2017_processed.csv ‚Üí data/clean/"
        ],

        "ARCHIVAR (no eliminar todav√≠a)": [
            "debug_ml_network_sniffer.py ‚Üí archive/debugging/",
            "fixed_ml_network_sniffer.py ‚Üí archive/debugging/",
            "unsw_audit.py ‚Üí archive/analysis/",
            "models/rf_production_final.joblib ‚Üí archive/corrupted_models/"
        ],

        "EVALUAR PARA ELIMINACI√ìN": [
            "advanced_trainer*.py ‚Üí posible eliminaci√≥n",
            "initial_trainer_models.py ‚Üí posible eliminaci√≥n",
            "threat-sniffer.py ‚Üí posible eliminaci√≥n",
            "UNSW-NB15.csv ‚Üí eliminar (corrupto)"
        ],

        "CREAR ESTRUCTURA NUEVA": [
            "core/ ‚Üí c√≥digo principal de producci√≥n",
            "tools/ ‚Üí herramientas de desarrollo/entrenamiento",
            "models/production/ ‚Üí modelos listos para release",
            "data/clean/ ‚Üí datasets limpios y validados",
            "archive/ ‚Üí c√≥digo legacy pero valioso",
            "docs/ ‚Üí documentaci√≥n de lecciones aprendidas"
        ]
    }

    for category, items in recommendations.items():
        print(f"\n{category}:")
        for item in items:
            print(f"   ‚úÖ {item}")

    print()


def generate_next_steps():
    """Genera pasos siguientes hacia la RELEASE"""

    print("üöÄ PR√ìXIMOS PASOS HACIA LA RELEASE:")
    print("=" * 40)

    next_steps = [
        "1. üßπ LIMPIEZA INMEDIATA:",
        "   - Crear estructura de directorios organizada",
        "   - Mover archivos seg√∫n recomendaciones",
        "   - Eliminar c√≥digo claramente obsoleto",
        "",
        "2. üîß REFINAMIENTO T√âCNICO:",
        "   - Optimizar fixed_service_sniffer.py para producci√≥n",
        "   - Mejorar logging y monitoring",
        "   - Configuraciones externalizadas",
        "",
        "3. üìö DOCUMENTACI√ìN:",
        "   - README completo del proyecto",
        "   - Lecciones aprendidas (timestamps, datasets, etc.)",
        "   - Gu√≠a de despliegue",
        "",
        "4. üß™ TESTING & VALIDACI√ìN:",
        "   - Suite de tests automatizados",
        "   - Validaci√≥n con tr√°fico real diverso",
        "   - Benchmarks de performance",
        "",
        "5. üöÄ PREPARACI√ìN RELEASE:",
        "   - Containerizaci√≥n (Docker)",
        "   - CI/CD pipeline",
        "   - Configuraci√≥n de producci√≥n",
        "",
        "6. üìä MONITORING & OBSERVABILITY:",
        "   - M√©tricas de sistema",
        "   - Alerting inteligente",
        "   - Dashboards de monitoreo"
    ]

    for step in next_steps:
        print(step)

    print()


def main():
    """Funci√≥n principal del audit"""

    print(f"Ejecutado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Directorio: {os.getcwd()}")
    print()

    # Ejecutar an√°lisis
    categories = analyze_project_files()
    analyze_models_and_data()
    generate_cleanup_recommendations()
    generate_next_steps()

    print("üéØ RESUMEN:")
    print(f"   - Hito INCRE√çBLE logrado: Sistema ML funcional ‚úÖ")
    print(f"   - Pr√≥ximo objetivo: Organizar para RELEASE üöÄ")
    print(f"   - Estado: Listo para limpieza y refinamiento üí™")

    print("\n" + "=" * 70)
    print("üèÜ ¬°EXCELENTE TRABAJO, ALONSO!")
    print("   El sistema funciona, ahora vamos por la RELEASE perfecta.")
    print("=" * 70)


if __name__ == "__main__":
    main()