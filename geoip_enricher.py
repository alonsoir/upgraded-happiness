# geoip_enricher.py - Completamente configurable desde JSON

import zmq
import json
import time
import logging
import threading
import sys
from queue import Queue, Empty
from typing import Dict, Any, Optional
from threading import Event


class ConfigurableGeoIPEnricher:
    """
    GeoIP Enricher completamente configurable desde JSON
    Sin valores por defecto hardcodeados - todo viene del archivo de configuraciÃ³n
    """

    def __init__(self, config_file: str):
        # ğŸ“„ Cargar configuraciÃ³n - SIN defaults hardcodeados
        self.config = self._load_config_strict(config_file)
        self.config_file = config_file

        # ğŸ·ï¸ node_id desde configuraciÃ³n
        self.node_id = self.config["node_id"]

        # ğŸ”Œ Setup ZeroMQ desde configuraciÃ³n
        self.context = zmq.Context()
        self.input_socket = None
        self.output_socket = None
        self.setup_sockets()

        # ğŸ”„ Backpressure desde configuraciÃ³n
        self.backpressure_config = self.config["backpressure"]

        # ğŸ“Š MÃ©tricas
        self.stats = {
            'received': 0,
            'enriched': 0,
            'sent': 0,
            'failed_lookups': 0,
            'buffer_errors': 0,
            'processing_errors': 0,
            'backpressure_activations': 0,
            'start_time': time.time(),
            'last_stats_time': time.time()
        }

        # ğŸ”„ Queue interno para procesamiento asÃ­ncrono
        queue_size = self.config["processing"]["internal_queue_size"]
        self.processing_queue = Queue(maxsize=queue_size)

        # ğŸ›ï¸ Control
        self.running = True
        self.stop_event = Event()

        # ğŸ“ Setup logging desde configuraciÃ³n
        self.setup_logging()

        self.logger.info(f"ğŸš€ GeoIP Enricher inicializado - node_id: {self.node_id}")
        self.logger.info(f"ğŸ“„ Config: {config_file}")

    def _load_config_strict(self, config_file: str) -> Dict[str, Any]:
        """
        Carga configuraciÃ³n SIN proporcionar defaults
        Si falta algo crÃ­tico, falla rÃ¡pido
        """
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
        except FileNotFoundError:
            raise RuntimeError(f"âŒ Archivo de configuraciÃ³n no encontrado: {config_file}")
        except json.JSONDecodeError as e:
            raise RuntimeError(f"âŒ Error parseando JSON: {e}")

        # âœ… Validar campos crÃ­ticos
        required_fields = [
            "node_id",
            "zmq",
            "backpressure",
            "processing",
            "geoip",
            "logging",
            "monitoring"
        ]

        for field in required_fields:
            if field not in config:
                raise RuntimeError(f"âŒ Campo requerido faltante en config: {field}")

        # âœ… Validar subcampos ZMQ
        zmq_required = ["input_port", "output_port", "recv_timeout_ms", "send_timeout_ms", "linger_ms"]
        for field in zmq_required:
            if field not in config["zmq"]:
                raise RuntimeError(f"âŒ Campo ZMQ requerido faltante: zmq.{field}")

        # âœ… Validar subcampos processing
        proc_required = ["threads", "internal_queue_size"]
        for field in proc_required:
            if field not in config["processing"]:
                raise RuntimeError(f"âŒ Campo processing requerido faltante: processing.{field}")

        # âœ… Validar subcampos backpressure
        bp_required = ["enabled", "max_retries", "retry_delays_ms"]
        for field in bp_required:
            if field not in config["backpressure"]:
                raise RuntimeError(f"âŒ Campo backpressure requerido faltante: backpressure.{field}")

        self._log_config_loaded(config)
        return config

    def _log_config_loaded(self, config: Dict[str, Any]):
        """Log de configuraciÃ³n cargada"""
        print(f"âœ… GeoIP Enricher configuraciÃ³n cargada:")
        print(f"   ğŸ·ï¸ Node ID: {config['node_id']}")
        print(f"   ğŸ“¥ Input Puerto: {config['zmq']['input_port']}")
        print(f"   ğŸ“¤ Output Puerto: {config['zmq']['output_port']}")
        print(f"   ğŸ”„ Backpressure: {'âœ…' if config['backpressure']['enabled'] else 'âŒ'}")
        print(f"   ğŸ§µ Threads: {config['processing']['threads']}")

    def setup_sockets(self):
        """ConfiguraciÃ³n ZMQ desde archivo de configuraciÃ³n"""
        zmq_config = self.config["zmq"]

        # ğŸ“¥ Socket de entrada (PULL)
        self.input_socket = self.context.socket(zmq.PULL)
        self.input_socket.setsockopt(zmq.RCVTIMEO, zmq_config["recv_timeout_ms"])

        input_port = zmq_config["input_port"]
        input_address = f"tcp://localhost:{input_port}"
        self.input_socket.connect(input_address)

        # ğŸ“¤ Socket de salida (PUSH)
        self.output_socket = self.context.socket(zmq.PUSH)
        self.output_socket.setsockopt(zmq.LINGER, zmq_config["linger_ms"])
        self.output_socket.setsockopt(zmq.SNDTIMEO, zmq_config["send_timeout_ms"])

        output_port = zmq_config["output_port"]
        output_address = f"tcp://*:{output_port}"
        self.output_socket.bind(output_address)

        print(f"ğŸ”Œ Sockets ZMQ configurados:")
        print(f"   ğŸ“¥ Input: {input_address}")
        print(f"   ğŸ“¤ Output: {output_address}")

    def setup_logging(self):
        """Setup logging desde configuraciÃ³n con node_id"""
        log_config = self.config["logging"]

        # ğŸ“ Configurar nivel
        level = getattr(logging, log_config["level"].upper())

        # ğŸ·ï¸ Formato con node_id
        formatter = logging.Formatter(
            log_config["format"].format(node_id=self.node_id)
        )

        # ğŸ”§ Configurar handler
        if log_config.get("file"):
            handler = logging.FileHandler(log_config["file"])
        else:
            handler = logging.StreamHandler()

        handler.setFormatter(formatter)

        # ğŸ“‹ Setup logger
        self.logger = logging.getLogger(f"geoip_enricher_{self.node_id}")
        self.logger.setLevel(level)
        self.logger.addHandler(handler)

        # ğŸ”‡ Evitar duplicados
        self.logger.propagate = False

    def apply_backpressure_output(self, attempt: int) -> bool:
        """
        Aplica backpressure para envÃ­o de salida segÃºn configuraciÃ³n
        """
        bp_config = self.backpressure_config

        if not bp_config["enabled"]:
            return False

        if attempt >= bp_config["max_retries"]:
            return False

        # ğŸ”„ Aplicar delay configurado
        delays = bp_config["retry_delays_ms"]
        if attempt < len(delays):
            delay_ms = delays[attempt]
        else:
            delay_ms = delays[-1]

        time.sleep(delay_ms / 1000.0)

        self.stats['backpressure_activations'] += 1
        return True

    def receive_events(self):
        """Thread de recepciÃ³n de eventos"""
        self.logger.info("ğŸ“¡ Iniciando thread de recepciÃ³n...")

        while self.running:
            try:
                # ğŸ“¨ Recibir evento con timeout
                data = self.input_socket.recv(zmq.NOBLOCK)
                self.stats['received'] += 1

                # ğŸ“‹ AÃ±adir a queue de procesamiento
                try:
                    queue_timeout = self.config["processing"]["queue_put_timeout_seconds"]
                    self.processing_queue.put(data, timeout=queue_timeout)
                except:
                    # Queue lleno - estadÃ­stica y descarte
                    self.stats['buffer_errors'] += 1
                    self.logger.warning("âš ï¸ Queue interno lleno - evento descartado")

            except zmq.Again:
                # Sin datos disponibles - continuar
                continue
            except zmq.ZMQError as e:
                self.logger.error(f"âŒ Error ZMQ recepciÃ³n: {e}")
                time.sleep(0.1)

    def process_events(self):
        """Thread de procesamiento de eventos"""
        self.logger.info("âš™ï¸ Iniciando thread de procesamiento...")

        queue_timeout = self.config["processing"]["queue_get_timeout_seconds"]

        while self.running:
            try:
                # ğŸ“‹ Obtener evento del queue
                data = self.processing_queue.get(timeout=queue_timeout)

                # ğŸŒ Enriquecer con GeoIP
                enriched_data = self.enrich_with_geoip(data)

                if enriched_data:
                    self.stats['enriched'] += 1
                    self.send_enriched_event_with_backpressure(enriched_data)
                else:
                    self.stats['processing_errors'] += 1

                self.processing_queue.task_done()

            except Empty:
                # Timeout normal - continuar
                continue
            except Exception as e:
                self.logger.error(f"âŒ Error procesamiento: {e}")
                self.stats['processing_errors'] += 1

    def enrich_with_geoip(self, raw_data: bytes) -> Optional[bytes]:
        """Enriquecimiento GeoIP usando configuraciÃ³n"""
        try:
            # ğŸ” Deserializar evento
            event = self.deserialize_event(raw_data)

            # ğŸŒ Lookup GeoIP usando configuraciÃ³n
            geoip_config = self.config["geoip"]
            coordinates = self.lookup_coordinates(event.get('source_ip'), geoip_config)

            if coordinates:
                event['latitude'] = coordinates[0]
                event['longitude'] = coordinates[1]
                event['geoip_enriched'] = True
                event['enrichment_node'] = self.node_id
                event['enrichment_timestamp'] = time.time()
            else:
                self.stats['failed_lookups'] += 1
                event['geoip_enriched'] = False

                # ğŸ”§ Aplicar coordenadas por defecto si estÃ¡ configurado
                if geoip_config.get("use_default_coordinates_on_failure", False):
                    default_coords = geoip_config["default_coordinates"]
                    event['latitude'] = default_coords[0]
                    event['longitude'] = default_coords[1]
                    event['geoip_enriched'] = True
                    event['geoip_source'] = 'default'

            return self.serialize_event(event)

        except Exception as e:
            self.logger.error(f"âŒ Error enriquecimiento: {e}")
            return None

    def send_enriched_event_with_backpressure(self, enriched_data: bytes) -> bool:
        """EnvÃ­o robusto con backpressure configurable"""
        bp_config = self.backpressure_config
        max_retries = bp_config["max_retries"]

        for attempt in range(max_retries + 1):
            try:
                self.output_socket.send(enriched_data, zmq.NOBLOCK)
                self.stats['sent'] += 1
                return True

            except zmq.Again:
                # Buffer de salida lleno
                self.stats['buffer_errors'] += 1

                if attempt == max_retries:
                    self.logger.warning("âš ï¸ Output buffer lleno - evento descartado tras reintentos")
                    return False

                # ğŸ”„ Aplicar backpressure
                if not self.apply_backpressure_output(attempt):
                    return False

                continue

            except zmq.ZMQError as e:
                self.logger.error(f"âŒ Error envÃ­o ZMQ: {e}")
                return False

        return False

    def lookup_coordinates(self, ip_address: str, geoip_config: Dict[str, Any]) -> Optional[tuple]:
        """Lookup GeoIP usando configuraciÃ³n"""
        if not ip_address or ip_address == 'unknown':
            return None

        # ğŸ” MÃ©todo de lookup desde configuraciÃ³n
        lookup_method = geoip_config["lookup_method"]

        if lookup_method == "mock":
            # ğŸ­ Mock para testing - coordenadas desde config
            return tuple(geoip_config["mock_coordinates"])

        elif lookup_method == "maxmind":
            # ğŸŒ MaxMind GeoIP (implementar segÃºn tu setup)
            # return self.lookup_maxmind(ip_address, geoip_config["maxmind"])
            # Por ahora mock
            return tuple(geoip_config["mock_coordinates"])

        elif lookup_method == "api":
            # ğŸŒ API externa (implementar segÃºn tu setup)
            # return self.lookup_api(ip_address, geoip_config["api"])
            # Por ahora mock
            return tuple(geoip_config["mock_coordinates"])

        else:
            self.logger.error(f"âŒ MÃ©todo de lookup desconocido: {lookup_method}")
            return None

    def deserialize_event(self, raw_data: bytes) -> Dict[str, Any]:
        """DeserializaciÃ³n segÃºn configuraciÃ³n"""
        serialization_config = self.config["processing"]["serialization"]
        format_type = serialization_config["format"]

        if format_type == "json":
            try:
                return json.loads(raw_data.decode(serialization_config["encoding"]))
            except:
                # ğŸ”§ Fallback a estructura bÃ¡sica
                return {'source_ip': 'unknown', 'target_ip': 'unknown'}

        elif format_type == "protobuf":
            # ğŸ“¦ Implementar deserializaciÃ³n protobuf segÃºn tu setup
            # Por ahora fallback
            return {'source_ip': 'unknown', 'target_ip': 'unknown'}

        else:
            self.logger.error(f"âŒ Formato de serializaciÃ³n desconocido: {format_type}")
            return {'source_ip': 'unknown', 'target_ip': 'unknown'}

    def serialize_event(self, event: Dict[str, Any]) -> bytes:
        """SerializaciÃ³n segÃºn configuraciÃ³n"""
        serialization_config = self.config["processing"]["serialization"]
        format_type = serialization_config["format"]

        if format_type == "json":
            try:
                return json.dumps(event).encode(serialization_config["encoding"])
            except:
                return b'{}'

        elif format_type == "protobuf":
            # ğŸ“¦ Implementar serializaciÃ³n protobuf segÃºn tu setup
            # Por ahora fallback
            return json.dumps(event).encode('utf-8')

        else:
            return b'{}'

    def monitor_stats(self):
        """Thread de monitoreo de estadÃ­sticas"""
        monitoring_config = self.config["monitoring"]
        interval = monitoring_config["stats_interval_seconds"]

        while self.running:
            time.sleep(interval)

            if not self.running:
                break

            self.log_performance_stats()
            self.check_performance_alerts()

    def log_performance_stats(self):
        """Log de estadÃ­sticas de performance"""
        now = time.time()
        interval = now - self.stats['last_stats_time']

        # ğŸ“Š Calcular rates
        recv_rate = self.stats['received'] / interval if interval > 0 else 0
        proc_rate = self.stats['enriched'] / interval if interval > 0 else 0
        send_rate = self.stats['sent'] / interval if interval > 0 else 0

        self.logger.info(f"ğŸ“Š GeoIP Stats:")
        self.logger.info(f"   ğŸ“¨ Recibidos: {self.stats['received']} ({recv_rate:.1f}/s)")
        self.logger.info(f"   ğŸŒ Enriquecidos: {self.stats['enriched']} ({proc_rate:.1f}/s)")
        self.logger.info(f"   ğŸ“¤ Enviados: {self.stats['sent']} ({send_rate:.1f}/s)")
        self.logger.info(f"   âŒ Errores: lookup={self.stats['failed_lookups']}, buffer={self.stats['buffer_errors']}")
        self.logger.info(f"   ğŸ“‹ Queue size: {self.processing_queue.qsize()}")
        self.logger.info(f"   ğŸ”„ Backpressure: {self.stats['backpressure_activations']} activaciones")

        # ğŸ”„ Reset stats for next interval
        for key in ['received', 'enriched', 'sent', 'failed_lookups', 'buffer_errors', 'backpressure_activations']:
            self.stats[key] = 0

        self.stats['last_stats_time'] = now

    def check_performance_alerts(self):
        """Verifica alertas de performance desde configuraciÃ³n"""
        monitoring_config = self.config["monitoring"]
        alerts = monitoring_config.get("alerts", {})

        # ğŸš¨ Alert de queue lleno
        queue_usage = self.processing_queue.qsize() / self.config["processing"]["internal_queue_size"]
        max_queue_usage = alerts.get("max_queue_usage_percent", 100) / 100.0

        if queue_usage > max_queue_usage:
            self.logger.warning(
                f"ğŸš¨ ALERTA: Queue interno lleno ({queue_usage * 100:.1f}% > {max_queue_usage * 100:.1f}%)")

        # ğŸš¨ Alert de errores de lookup altos
        total_lookups = self.stats['enriched'] + self.stats['failed_lookups']
        if total_lookups > 0:
            failure_rate = (self.stats['failed_lookups'] / total_lookups) * 100
            max_failure_rate = alerts.get("max_geoip_failure_rate_percent", 100)

            if failure_rate > max_failure_rate:
                self.logger.warning(f"ğŸš¨ ALERTA: Tasa de fallo GeoIP alta ({failure_rate:.1f}% > {max_failure_rate}%)")

    def run(self):
        """Ejecutar el enriquecedor"""
        self.logger.info("ğŸš€ Iniciando Enhanced GeoIP Enricher...")

        # ğŸ§µ Crear threads segÃºn configuraciÃ³n
        threads = []

        # Thread de recepciÃ³n
        recv_thread = threading.Thread(target=self.receive_events, name="Receiver")
        threads.append(recv_thread)

        # Threads de procesamiento segÃºn configuraciÃ³n
        num_processing_threads = self.config["processing"]["threads"]
        for i in range(num_processing_threads):
            proc_thread = threading.Thread(target=self.process_events, name=f"Processor-{i}")
            threads.append(proc_thread)

        # Thread de estadÃ­sticas
        stats_thread = threading.Thread(target=self.monitor_stats, name="Monitor")
        threads.append(stats_thread)

        # ğŸš€ Iniciar todos los threads
        for thread in threads:
            thread.start()

        self.logger.info(f"âœ… GeoIP Enricher iniciado con {len(threads)} threads")

        try:
            # ğŸ”„ Mantener vivo el proceso principal
            while self.running:
                time.sleep(1)
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ Deteniendo GeoIP Enricher...")

        # ğŸ›‘ Cierre graceful
        self.shutdown(threads)

    def shutdown(self, threads):
        """Cierre graceful del enriquecedor"""
        self.running = False
        self.stop_event.set()

        # ğŸ“Š Stats finales
        runtime = time.time() - self.stats['start_time']
        self.logger.info(f"ğŸ“Š Stats finales - Runtime: {runtime:.1f}s")
        self.logger.info(f"   Total procesados: {self.stats['enriched']}")

        # ğŸ§µ Esperar threads
        for thread in threads:
            thread.join(timeout=5)

        # ğŸ”Œ Cerrar sockets
        if self.input_socket:
            self.input_socket.close()
        if self.output_socket:
            self.output_socket.close()

        self.context.term()

        self.logger.info("âœ… GeoIP Enricher cerrado correctamente")


# ğŸš€ Main
if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("âŒ Uso: python geoip_enricher.py <config.json>")
        sys.exit(1)

    config_file = sys.argv[1]

    try:
        enricher = ConfigurableGeoIPEnricher(config_file)
        enricher.run()
    except Exception as e:
        print(f"âŒ Error fatal: {e}")
        sys.exit(1)